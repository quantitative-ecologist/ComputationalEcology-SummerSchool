
---
title: Sentinelle Nord Advanced Field School in Computational Ecology
subtitle: Analysis of predator foraging behaviour using multivariate linear mixed models
author:
  - name: Maxime Fraser Franco
    affiliation: Département des Sciences Biologiques & Centre de la Science de la Biodiversité du Québec, Université du Québec à Montréal
    email: fraser_franco.maxime@courrier.uqam.ca
  - name: Pierre-Olivier Montiglio
    affiliation: Département des Sciences Biologiques & Centre de la Science de la Biodiversité du Québec, Université du Québec à Montréal
    email: montiglio.pierre-olivier@uqam.ca
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    css: style.css
    number_sections: yes
    toc: yes
    toc_float: yes
    highlight: zenburn
    theme: flatly
    df_print: paged
    code_folding: hide
bibliography: references1.bib
nocite: |
  @McElreath2020
  @Burkner2017
  @Burkner2018
  @FraserFranco.etal2022
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  fig.align = "center",
  warning = FALSE,
  message = FALSE
)
```

---

<br>



# Overview

This tutorial is part of the behavioural ecology work package presented during the [Sentinelle Nord advanced field school in computational ecology](http://dev.sentinellenord.ulaval.ca/en/ecology2023) held in May 2023 in Val-Morin, Québec, Canada.

In this tutorial, we will analyze behavioural data from the online videogame [Dead by Daylight](https://deadbydaylight.com/). This game simulates a predator-prey interaction where one predator player hunts four prey players in a virtual environment. It thus represents a similar system to the TrophIE game that was developed during the summer school where humans interact in a simulated predator-prey game.

The analyses that we will conduct are derived from this study :

- Fraser Franco, M., Santostefano, F., Kelly, C. D., Montiglio, P.-O. (2022) Studying predator foraging mode and hunting success at the individual level with an online videogame. *Behavioral Ecology*, *33*(5), 967-978. [https://doi.org/10.1093/beheco/arac063](https://doi.org/10.1093/beheco/arac063)

- Fraser Franco, M., Santostefano, F., Kelly, C. D., Montiglio, P.-O. (2022). Data from: studying predator foraging mode and hunting success at the individual level with an online videogame. *Behavioral Ecology*. [https://doi.org/10.17605/OSF.IO/WYVRT](https://doi.org/10.17605/OSF.IO/WYVRT)

The code and data to reproduce the analyses presented in the aforementioned paper are freely available on [GitHub](https://github.com/quantitative-ecologist/predator-foraging-mode-videogames)

<br>



# Case study

In the study by Fraser Franco et al. (2022), the authors were interested in mapping the predator's foraging tactics at different levels of biological organization (among environments, individuals, and within individuals). They were also investigating which foraging tactics were most successful, and if their success depended on the behaviour of the prey being hunted.

To do so, they employed multivariate linear mixed models, an extension of standard mixed models where multiple response variables can be modeled simultaneously, and where relationships among the random effects of those response variables are estimated.

Here, we will work with a simpler version of the models presented in the paper. All the results presented in the present workshop can be reproduced using the files provided in this [GitHub repository](https://github.com/quantitative-ecologist/ComputationEcology-SummerSchool)

<br>



# The data

The player behaviour data was collected by the videogame company Behaviour Interactive between March 20 2019 and June 17 2019. Every player initiated their first match between March 20 and March 22. This dataset summarizes behavioural data from matches played as the predator. For every match, the date (date-hour-minutes), the duration (seconds), the predator player's anonymous ID, the predator's avatar, and the game environment were recorded along with the predator and prey behaviours.

Here is some basic information on the dataset : 
 - Matches were played exclusively against a group of unknown people.
 - Minimum match duration was 5 minutes
 - Population of 2 378 players
 - 77 047 matches (average: 34 matches per individual, range: 1-1059 matches)
 - The average match duration was 11.13 minutes (range: 5-35 min).


## Load the libraries

In this tutorial, we will use the [`data.table`](https://rdatatable.gitlab.io/data.table/index.html) R package for data wrangling. `data.table` is a fast and very useful package for data science in general, and is great for manipulating large datasets. It operates similarly to base R's `data.frame`.

We will fit all our models using the package [`brms`](https://paul-buerkner.github.io/brms/), which is an R front-end for the probabilistic language [STAN](https://mc-stan.org/) software. `brms` uses Hamiltonian Monte Carlo (HMC) and the no-U-turn sampler (NUTS) to estimate the model parameters.

Lastly, we use the [`ggplot2`](https://ggplot2.tidyverse.org/) R package for our plots, and [`ggpubr`](https://rpkgs.datanovia.com/ggpubr/index.html) to combine multiple plots together.

```{r, class.source = "fold-show"}

# libraries
library(data.table)
library(brms)
library(ggplot2)
library(ggpubr)
```


## Import the data

We directly import the data hosted on the public GitHub repository into our session.

```{r, class.source = "fold-show"}

# Type the repository's URL
github <- "https://raw.githubusercontent.com/quantitative-ecologist"
repository <- "predator-foraging-mode-videogames"
folder <- "main/data"

# Import the data in our session
data <- fread(
  file.path(
    github, repository,
    folder, "FraserFrancoetal2022-data.csv"
  ),
  select = c(
    "player_id", "avatar_id",
    "hunting_success", "game_duration",
    "speed", "space_covered_rate", "hook_start_time",
    "prey_avg_speed", "prey_avg_space_covered_rate"
  )
)

# Rename variables
setnames(data, "hook_start_time", "latency_1st_capture")
setnames(data, "speed", "pred_speed")
setnames(data, "player_id", "predator_id")
```


## Data exploration

### Data structure

PO : ici je prendrais le temps de décrire un peu les variables et ce qu'elles représentent. 

```{r, class.source = "fold-show"}
# Print the data
data

# Inspect the number of avatars
length(unique(data$avatar_id))

# Inspect the number of individual predators
length(unique(data$predator_id))
```

### Distribution of variables
```{r histograms-data, out.width="100%", out.height="70%"}

# Reshape the data to plot multiple histograms -----------------------------------

# Select the needed variables
dat_hist <- data[
  , .(
    pred_speed, space_covered_rate,
    prey_avg_speed, prey_avg_space_covered_rate,
    latency_1st_capture, game_duration
  )
]

# Reshape the table
dat_hist <- melt(
  data = dat_hist,
  variable.name = "variable",
  value.name = "value"
)



# Plot the histograms ------------------------------------------------------------

# Panel labels
labels <- labeller(
  variable =
  c("pred_speed" = "Predator speed",
    "space_covered_rate" = "Rate of space coverage",
    "prey_avg_speed" = "Prey speed",
    "prey_avg_space_covered_rate" = "Prey's rate of space coverage",
    "latency_1st_capture" = "Latency for 1st capture",
    "game_duration" = "Game duration")
)

p <- ggplot(data = dat_hist, aes(x = value)) +
  geom_histogram(col = "black", fill = "gray") +
  xlab("\nValue") +
  ylab("Frequency\n") +
  facet_wrap(~ variable, scales = "free", labeller = labels) +
  theme_bw(base_size = 12) +
  theme(panel.grid = element_blank(), strip.text = element_text(size = 8))

# Show figure
p
```

<br>



# Fitting multivariate linear mixed effects model with `brms`


## Transforming and standardizing our variables

```{r, class.source = "fold-show"}

# Transform our variables
data[, ":=" (
  latency_1st_capture = log(latency_1st_capture + 1),
  game_duration = sqrt(game_duration)
  )
]

# Standardize the variables
standardize <- function(x) {
  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
}

data[
  , c("Zgame_duration",
      "Zpred_speed",
      "Zspace_covered_rate",
      "Zlatency_1st_capture",
      "Zprey_avg_speed", 
      "Zprey_avg_space_covered_rate") :=
  lapply(.SD, standardize),
  .SDcols = c(4:9)
]
```


## Building the models

### Model 1 - Hunting tactics without controlling for prey behaviour

The following block of code shows the formula for the three traits we are modelling :
- The predators's speed
- The predator's rate of space covered
- The predator's latency before the first prey is captured

We use the `bf()` (for "**b**rms **f**ormula") in `brms` to write the model formulas.
For the predator's speed and rate of space covered, the model estimates a general intercept and two random effects which are the `avatar_id` and the `predator_id`. The model for the predator's latency before the first capture follows the same structure, but we include the match duration (`Zgame_duration`) as a fixed effect to control for differences in game length.
The three sub models are modeled assuming a Gaussian distribution family of the residuals.

```{r, class.source = "fold-show"}

# Model for the predator's speed
speed_form1 <- bf(
  Zpred_speed ~
  1 +
  (1 | a | avatar_id) +
  (1 | b | predator_id)
) + gaussian()

# Model for the rate of space covered by the predator
space_form1 <- bf(
  Zspace_covered_rate ~
  1 +
  (1 | a | avatar_id) +
  (1 | b | predator_id)
) + gaussian()

# Model for the latency before the 1st capture
hook_form1 <- bf(
  Zlatency_1st_capture ~
  1 +
  Zgame_duration +
  (1 | a | avatar_id) +
  (1 | b | predator_id)
) + gaussian()
```

### Model 2 - Hunting tactics controlling for prey behaviour

The second model follows the same structure as the first, but includes the average speed and rate of space covered of the prey group (`Zprey_avg_speed` and `Zprey_avg_space_covered_rate`) as fixed effects for the three predator traits.

```{r, class.source = "fold-show"}

# Model for the predator's speed
speed_form2 <- bf(
  Zpred_speed ~
  1 +
  Zprey_avg_speed +
  Zprey_avg_space_covered_rate +
  (1 | a | avatar_id) +
  (1 | b | predator_id)
) + gaussian()

# Model for the rate of space covered by the predator
space_form2 <- bf(
  Zspace_covered_rate ~
  1 +
  Zprey_avg_speed +
  Zprey_avg_space_covered_rate +
  (1 | a | avatar_id) +
  (1 | b | predator_id)
) + gaussian()

# Model for the latency before the 1st capture
hook_form2 <- bf(
  Zlatency_1st_capture ~
  1 +
  Zprey_avg_speed +
  Zprey_avg_space_covered_rate +
  Zgame_duration +
  (1 | a | avatar_id) +
  (1 | b | predator_id)
) + gaussian()
```

### Setting up priors

Lastly, the Bayesian approach requires that we define priors for the parameters that the models will estimate. (brief explanation here). You can read more on priors in the following sources :

- source1
- source2
- source3

```{r, class.source = "fold-show"}

# Priors for model 1
priors1 <- c(
  # priors on fixed effects
  set_prior(
    "normal(0, 2)",
    class = "b",
    coef = "Zgame_duration",
    resp = "Zlatency1stcapture"
  ),
  # priors on var. parameters (brms automatically detects half-normal)
  set_prior(
    "normal(0, 1)",
    class = "sd", # applies to all variance parameters
    resp = c("Zpredspeed", "Zspacecoveredrate", "Zlatency1stcapture")
  ),
  # priors on the variance-covariance matrices
  set_prior(
    "lkj(2)",
    class = "cor",
    group = "avatar_id"
  ),
  set_prior(
    "lkj(2)",
    class = "cor",
    group = "predator_id"
  )
)

# Priors for model 2
priors2 <- c(
  priors1,
  set_prior(
    "normal(0, 2)",
    class = "b",
    coef = c("Zprey_avg_speed", "Zprey_avg_space_covered_rate"),
    resp = c("Zpredspeed", "Zspacecoveredrate", "Zlatency1stcapture",
             "Zpredspeed", "Zspacecoveredrate", "Zlatency1stcapture")
  )
)
```


## Run the models

**Import the model into our session**

Estimating model parameters with MCMC can take a long time. You should thus save your models outputs as R objects when they are finished running. You can then reupload the model objects into an R session and manipulate them for your needs (e.g. for plots and tables).

This is what we do here, we will directly import the two model outputs from our "models" folder (`.rds` files) as R objects into our session.

```{r, class.source = "fold-show"}

path <- file.path(getwd(), "models")

fit1 <- readRDS(file.path(path, "mv_model1.rds"))
fit2 <- readRDS(file.path(path, "mv_model2.rds"))
```


**Code for Model 1 where we do not account for prey behaviour :**

Here is the `brms` code that was used to run the first model (`fit1`) that we just imported. We used the `brm()` function to parameterize and initiate the sampling.

PO even if we do not want them to run the models, I would spend a little bit more time here going over the arguments? I would still avoid falling into the rabbit hole of everything one needs to know to fit a bayesian model, but just cite the relevant work for someone who would like to run models properly. 

```{r eval = FALSE, class.source = "fold-show"}

# Model 1
fit1 <- brm(
  # The three model formulas are summed
  speed_form1 +
  space_form1 +
  hook_form1 +
  # To estimate residual correlations
  # i.e. inference about behavioural plasticity
  set_rescor(TRUE),
  # MCMC settings to obtain 1000 posterior samples
  # (iter - warmups) / thin * chains
  warmup = 500,
  iter = 2500,
  thin = 8,
  chains = 4,
  # Initialize parameter values at 0
  inits = "0",
  # Within-chain parallelization :
  # Use only if you have access to multiple computer cores
  threads = threading(10),
  # Software backend for MCMC estimation
  backend = "cmdstanr",
  seed = 123,
  prior = priors1,
  # Helps MCMC convergence
  control = list(adapt_delta = 0.95),
  # Sample priors to later compare priors vs posterior distributions
  sample_prior = TRUE,
  data = data
)

# Save the object to a specified folder path
my_path <- file.path(getwd(), "your_folder")
saveRDS(fit1, file = file.path(my_path, "mv_model1.rds"))
```

**Code for Model 2 where we control for prey behaviour :**

And here is the `brms` code used to fit the second model, where we controlled for the prey's behaviour (`fit1`).

```{r eval = FALSE, class.source = "fold-show"}

# Model 1
fit2 <- brm(
  # The three model formulas are summed
  speed_form2 +
  space_form2 +
  hook_form2 +
  # To estimate residual correlations
  # i.e. inference about behavioural plasticity
  set_rescor(TRUE),
  # MCMC settings to obtain 1000 posterior samples
  # (iter - warmups) / thin * chains
  warmup = 500,
  iter = 2500,
  thin = 8,
  chains = 4,
  # Initialize parameter values at 0
  inits = "0",
  # Within-chain parallelization :
  # Use only if you have access to multiple computer cores
  threads = threading(10),
  # Software backend for MCMC estimation
  backend = "cmdstanr",
  seed = 123,
  prior = priors,
  # Helps MCMC convergence
  control = list(adapt_delta = 0.95),
  # Sample priors to later compare priors vs posterior distributions
  sample_prior = TRUE,
  data = data
)

# Save the object to a specified folder path
my_path <- file.path(getwd(), "your_folder")
saveRDS(fit2, file = file.path(my_path, "mv_model2.rds"))
```


PO Perhaps a few sentences here explaining what the model fitting does? 
Just to introduce quickle the chains? and set the table for the next section on diagnostics, where we play with these components. 

## Model diagnostics

### Inspect model convergence

We first inspect the convergence of the chains for every parameter of interest using trace plots. We can deduce that the chains converged well when the trace plots are homogeneous.

We start by extracting the model parameters that we want in a `data.frame`.

```{r, class.source = "fold-show"}

params <- as_draws_df(
  fit1, add_chain = TRUE,
  variable = c("^b_", "^sd", "^cor_", "^rescor_"),
  regex = TRUE
)
```

Inspect the trace plots for the beta parameters (intercepts + slopes)

```{r trace1, out.width="90%", out.height="70%"}
bayesplot::mcmc_trace(params, regex_pars = "b", np = nuts_params(fit1))
```

Inspect the trace plots for the standard deviation parameters (random effects)

```{r trace2, out.width="90%", out.height="50%"}
bayesplot::mcmc_trace(params, regex_pars = "sd", np = nuts_params(fit1))
```

Inspect the trace plots for the correlated random effects + the residual correlations

```{r trace3, out.width="90%", out.height="70%"}
bayesplot::mcmc_trace(params, regex_pars = "cor", np = nuts_params(fit1))
```

### Inspect the residuals

Here, we inspect our linear model assumptions by :
 - confirming that the residuals follow a gaussian distribution
 - confirming that the variance of the residuals is homogeneous

We start by extracting the fitted values and residuals for both models

```{r resid-mod1, cache = TRUE, class.source = "fold-show"}

# Residuals for model 1
fitted1a <- fitted(fit1, resp = "Zpredspeed")[, 1]
resid1a <- residuals(fit1, resp = "Zpredspeed")[, 1]

fitted1b <- fitted(fit1, resp = "Zspacecoveredrate")[, 1]
resid1b <- residuals(fit1, resp = "Zspacecoveredrate")[, 1]

fitted1c <- fitted(fit1, resp = "Zlatency1stcapture")[, 1]
resid1c <- residuals(fit1, resp = "Zlatency1stcapture")[, 1]
```

```{r resid-mod2, cache = TRUE, class.source = "fold-show"}
# Residuals for model 2
fitted2a <- fitted(fit2, resp = "Zpredspeed")[, 1]
resid2a <- residuals(fit2, resp = "Zpredspeed")[, 1]

fitted2b <- fitted(fit2, resp = "Zspacecoveredrate")[, 1]
resid2b <- residuals(fit2, resp = "Zspacecoveredrate")[, 1]

fitted2c <- fitted(fit2, resp = "Zlatency1stcapture")[, 1]
resid2c <- residuals(fit2, resp = "Zlatency1stcapture")[, 1]

```

We then produce the plots and combine them together to inspect their distribution.

```{r residplot-mod1, fig.height = 5, fig.width = 15}

assum1a <- ggplot() +
  geom_point(aes(x = fitted1a, y = resid1a), shape = 20, alpha = 0.05) +
  scale_y_continuous(breaks = seq(-6, 6, 2), limits = c(-7.55, 6)) +
  ggtitle("Speed - model 1") +
  xlab("Fitted values") + ylab("Residuals") +
  theme_bw() +
  theme(
    title = element_text(size = 15),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 15),
    panel.grid = element_blank()
    )
assum1a <- ggExtra::ggMarginal(assum1a, type = "histogram", margins = "y")

assum1b <- ggplot() +
  geom_point(aes(x = fitted1b, y = resid1b), shape = 20, alpha = 0.05) +
  scale_y_continuous(breaks = seq(-6, 6, 2), limits = c(-7.55, 6)) +
  ggtitle("Space covered - model 1") +
  xlab("Fitted values") + ylab("Residuals") +
  theme_bw() +
  theme(
    title = element_text(size = 15),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 15),
    panel.grid = element_blank()
    )
assum1b <- ggExtra::ggMarginal(assum1b, type = "histogram", margins = "y")

assum1c <- ggplot() +
  geom_point(aes(x = fitted1c, y = resid1c), shape = 20, alpha = 0.05) +
  scale_y_continuous(breaks = seq(-6, 6, 2), limits = c(-7.55, 6)) +
  ggtitle("Latency 1st capture - model 1") +
  xlab("Fitted values") + ylab("Residuals") +
  theme_bw() +
  theme(
    title = element_text(size = 15),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 15),
    panel.grid = element_blank()
    )
assum1c <- ggExtra::ggMarginal(assum1c, type = "histogram", margins = "y")

# Combine all plots into a single figure
resids1 <- ggarrange(
  assum1a, assum1b, assum1c,
  ncol = 3, nrow = 1
)

resids1
```

```{r residplot-mod2, fig.height = 5, fig.width = 15}
assum2a <- ggplot() +
  geom_point(aes(x = fitted2a, y = resid2a), shape = 20, alpha = 0.05) +
  scale_y_continuous(breaks = seq(-8, 6, 2), limits = c(-8, 6)) +
  ggtitle("Speed - model 2") +
  xlab("Fitted values") + ylab("Residuals") +
  theme_bw() +
  theme(
    title = element_text(size = 15),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 15),
    panel.grid = element_blank()
    )
assum2a <- ggExtra::ggMarginal(assum2a, type = "histogram", margins = "y")

assum2b <- ggplot() +
  geom_point(aes(x = fitted2b, y = resid2b), shape = 20, alpha = 0.05) +
  scale_y_continuous(breaks = seq(-8, 6, 2), limits = c(-8, 6)) +
  ggtitle("Space covered - model 2") +
  xlab("Fitted values") + ylab("Residuals") +
  theme_bw() +
  theme(
    title = element_text(size = 15),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 15),
    panel.grid = element_blank()
    )
assum2b <- ggExtra::ggMarginal(assum2b, type = "histogram", margins = "y")

assum2c <- ggplot() +
  geom_point(aes(x = fitted2c, y = resid2c), shape = 20, alpha = 0.05) +
  scale_y_continuous(breaks = seq(-8, 6, 2), limits = c(-8, 6)) +
  ggtitle("Latency 1st capture - model 2") +
  xlab("Fitted values") + ylab("Residuals") +
  theme_bw() +
  theme(
    title = element_text(size = 15),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 15),
    panel.grid = element_blank()
    )
assum2c <- ggExtra::ggMarginal(assum2c, type = "histogram", margins = "y")

# Combine all plots into a single figure
resids2 <- ggarrange(
  assum2a, assum2b, assum2c,
  ncol = 3, nrow = 1, heights = c(0.5, 0.5, 0.5)
)

resids2
```

### Inspect model fit

We can then investigate how well the models predicted the data using [posterior predictive checks](https://mc-stan.org/bayesplot/reference/PPC-overview.html). Producing the plots may take some time depending on the complexity of your model and the size of your data. You can specify the number of draws to display using the `ndraws` argument within the `pp_check()` function.

```{r ppchek1-mod1, cache = TRUE}

# Model 1
pp1a <- pp_check(fit1, resp = "Zpredspeed") +
  ggtitle("Speed")
pp1b <- pp_check(fit1, resp = "Zspacecoveredrate") +
  ggtitle("Rate of space covered")
pp1c <- pp_check(fit1, resp = "Zlatency1stcapture") +
  ggtitle("Latency 1st capture")
```

```{r ppchek1-mod2, cache = TRUE}
# Model 2
pp2a <- pp_check(fit2, resp = "Zpredspeed") +
  ggtitle("Speed")
pp2b <- pp_check(fit2, resp = "Zspacecoveredrate") +
  ggtitle("Rate of space covered")
pp2c <- pp_check(fit2, resp = "Zlatency1stcapture") +
  ggtitle("Latency 1st capture")
```

We now assemble the posterior predictive checks plots into one figure for model 1

```{r ppcheck1-fig1, out.width="70%", out.height="70%"}

fig1 <- ggarrange(
  pp1a, pp1b, pp1c,
  ncol = 2, nrow = 2,
  common.legend = TRUE
)

fig1
```

Posterior predictive checks plots into one figure for model 2

```{r ppcheck1-fig2, out.width="70%", out.height="70%"}

fig2 <- ggarrange(
  pp2a, pp2b, pp2c,
  ncol = 2, nrow = 2,
  common.legend = TRUE
)

fig2
```

Overall, we can see that : 
 - the chains converged well
 - the model is not too bad at predicting the data 
 - and the residuals seem to be OK.
 
Yet, some improvements could make our models better. For instance, we could use more informative priors based on the scientific knowledge of the system (and other predator-prey systems) to improve the model fit. It is also possible that including other variables in our model could improve the predictions. Sometimes, it can also be helpful to increase the number of iterations in the model and posterior samples to have a better fit.

### Additional checks

While the model verifications that we just did are probably among the most important ones, they cover only a small portion of the checks that you should perform to ensure that your model has been correctly specified. To go further, here is a list of useful links for additional checks: 

 - [MCMC diagnostics](https://mc-stan.org/bayesplot/articles/visual-mcmc-diagnostics.html) with the `bayesplot` package
 - [Additional posterior predictive checks](https://mc-stan.org/bayesplot/articles/graphical-ppcs.html) with the `bayesplot` package
 - [Additional residuals inspections](http://mjskay.github.io/tidybayes/articles/tidybayes-residuals.html) with the `tidybayes` package

Moreover, note that MCMC estimation can come with different convergence problems. Those problems can arise from different processes, but there will usually be a warning after the model fit telling you the problem. Here is a [useful link](https://mc-stan.org/misc/warnings.html) describing each of those problems, and the solutions that you can use to correct them.

<br>



# Interpret the models' results

## Fixed effects: population-level parameters

First, we may be interested in evaluating the fixed effects of our models. To ensure that the parameters are reliable, we will display their respective R-hat and effective sample sizes. We use a treshold of <1.01 for the R-hat values, and a threshold of <100 effective sample sizes as a decision rule for whether the model converged [@Burkner2017;@Vehtari.etal2021a].

```{r, class.source = "fold-show"}

# Prepare a data.table for model1
checks1_1 <- data.table(
  Model = "model1",
  round(summary(fit1)$fixed[, c(5:7)], digits = 3),
  keep.rownames = TRUE
)
setnames(checks1_1, old = "rn", new = "Parameter")

# Prepare a data.table for model1
checks1_2 <- data.table(
  Model = "model2",
  round(summary(fit2)$fixed[, c(5:7)], digits = 3),
  keep.rownames = TRUE
)
setnames(checks1_2, old = "rn", new = "Parameter")

# Combine as one table
checks1 <- rbind(checks1_1, checks1_2)
checks1
```

We see that the values are within our thresholds. We can thus assume that the models converged, and proceed to evaluate and interpret the parameter values. We use the `summary()` function to display them along with their credible intervals.

```{r, class.source = "fold-show"}

# Select the fixed effects values with their 95% CIs in a data.table for model1
fixed1_1 <- data.table(
  Model = "model1",
  round(summary(fit1)$fixed[, c(1, 3, 4)], digits = 3),
  keep.rownames = TRUE
)
setnames(fixed1_1, old = "rn", new = "Parameter")

# Select the fixed effects values with their 95% CIs in a data.table for model2
fixed1_2 <- data.table(
  Model = "model2",
  round(summary(fit2)$fixed[, c(1, 3, 4)], digits = 3),
  keep.rownames = TRUE
)
setnames(fixed1_2, old = "rn", new = "Parameter")

# Combine the results from both models as one table
fixed1 <- rbind(fixed1_1, fixed1_2)
fixed1
```

## Random effects: group-level parameters

### Avatar ID: Differences in behaviour among the predator avatars

We now inspect the random effects for the `avatar_id`. As we did with the fixed effects, we start by confirming whether the model converged by verifying the R-hats and effective sample sizes.

```{r, class.source = "fold-show"}

checks2_1 <- data.table(
  Model = "model1",
  round(summary(fit1)$random$avatar_id[, c(5:7)], digits = 3),
  keep.rownames = TRUE
)
setnames(checks2_1, old = "rn", new = "Parameter")

checks2_2 <- data.table(
  Model = "model2",
  round(summary(fit2)$random$avatar_id[, c(5:7)], digits = 3),
  keep.rownames = TRUE
)
setnames(checks2_2, old = "rn", new = "Parameter")

checks2 <- rbind(checks2_1, checks2_2)
checks2
```

All the values seem to fall below the tresholds. We can now inspect the parameter values. In `brms`, the random effects are displayed as standard deviations (`sd`). Thus, the random effects in our models are standard deviations estimated for each predator trait. The value of the standard deviations indicates whether predator avatars differ in their predicted average behaviours. For example, the value of `0.305` for the predator's speed indicates that there are differences among avatars in their average speed. Thus, some avatars are slower while others are faster.

The correlations (`cor`) between the predator avatars' average behaviours indicates whether, for example, avatars that were faster also captured their first prey faster (e.g. `cor(Zpredspeed_Intercept,Zlatency1stcapture_Intercept)`).

```{r, class.source = "fold-show"}

# Select the random effects with the estimated value along with their 95% CIs.
ranefs1_1 <- data.table(
  Model = "model1",
  round(summary(fit1)$random$avatar_id[, c(1, 3, 4)], digits = 3),
  keep.rownames = TRUE
)
setnames(ranefs1_1, old = "rn", new = "Parameter")

ranefs1_2 <- data.table(
  Model = "model2",
  round(summary(fit2)$random$avatar_id[, c(1, 3, 4)], digits = 3),
  keep.rownames = TRUE
)
setnames(ranefs1_2, old = "rn", new = "Parameter")

ranefs1 <- rbind(ranefs1_1, ranefs1_2)
ranefs1
```

### Predator ID : Differences in behaviour among the individual predator players

```{r, class.source = "fold-show"}

checks3_1 <- data.table(
  Model = "model1",
  round(summary(fit1)$random$avatar_id[, c(5:7)], digits = 3),
  keep.rownames = TRUE
)
setnames(checks3_1, old = "rn", new = "Parameter")

checks3_2 <- data.table(
  Model = "model2",
  round(summary(fit2)$random$avatar_id[, c(5:7)], digits = 3),
  keep.rownames = TRUE
)
setnames(checks3_2, old = "rn", new = "Parameter")

checks3 <- rbind(checks3_1, checks3_2)
checks3
```

```{r, class.source = "fold-show"}

# Select the random effects with the estimated value along with their 95% CIs.
ranefs2_1 <- data.table(
  Model = "model1",
  round(summary(fit1)$random$predator_id[, c(1, 3, 4)], digits = 3),
  keep.rownames = TRUE
)
setnames(ranefs2_1, old = "rn", new = "Parameter")

ranefs2_2 <- data.table(
  Model = "model2",
  round(summary(fit2)$random$predator_id[, c(1, 3, 4)], digits = 3),
  keep.rownames = TRUE
)
setnames(ranefs2_2, old = "rn", new = "Parameter")

ranefs2 <- rbind(ranefs2_1, ranefs2_2)
ranefs2

```

## Correlations among the random effects

We now...

<br>


# References {.unnumbered}

<div id="refs"></div>
