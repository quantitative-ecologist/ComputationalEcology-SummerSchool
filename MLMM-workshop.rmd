---
title: BIOS2 - Sentinelle Nord - Advanced Field School in Computational Ecology
subtitle: Analysis of predator foraging behaviour using multivariate linear mixed models
author:
  - name: | 
        Maxime Fraser Franco : \
        *developed the code for analyses and the Rmarkdown document*
    affiliation: Département des Sciences Biologiques & Centre de la Science de la Biodiversité du Québec, Université du Québec à Montréal
    email: fraser_franco.maxime@courrier.uqam.ca
  - name: | 
        Pierre-Olivier Montiglio : \
        *developed the teaching material*
    affiliation: Département des Sciences Biologiques & Centre de la Science de la Biodiversité du Québec, Université du Québec à Montréal
    email: montiglio.pierre-olivier@uqam.ca
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    css: style.css
    number_sections: yes
    toc: yes
    toc_float: yes
    highlight: zenburn
    theme: flatly
    df_print: paged
    code_folding: hide
bibliography: references.bib
nocite: |
  @McElreath2020
  @Burkner2017
  @Burkner2018
  @FraserFranco.etal2022
  @Piironen.Vehtari2017
  @aczelDiscussionPointsBayesian2020
  @kruschkeBayesianAnalysisReporting2021
  @Vehtari.etal2017
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  fig.align = "center",
  warning = FALSE,
  message = FALSE
)
```

---

<br>



# Overview

This tutorial is part of the behavioural ecology work package presented during the [BIOS2 - Sentinelle Nord - advanced field school in computational ecology](http://dev.sentinellenord.ulaval.ca/en/ecology2023) held in May 2023 in Val-Morin, Québec, Canada.

In this tutorial, we will analyze behavioural data from the online videogame [Dead by Daylight](https://deadbydaylight.com/). This game simulates a predator-prey interaction where one predator player hunts four prey players in a virtual environment. It thus represents a similar system to the TrophIE game that was developed during the summer school where humans interact in a simulated predator-prey game.

The analyses that we will conduct are derived from this study :

- Fraser Franco, M., Santostefano, F., Kelly, C. D., Montiglio, P.-O. (2022) Studying predator foraging mode and hunting success at the individual level with an online videogame. *Behavioral Ecology*, *33*(5), 967-978. [https://doi.org/10.1093/beheco/arac063](https://doi.org/10.1093/beheco/arac063)

- Fraser Franco, M., Santostefano, F., Kelly, C. D., Montiglio, P.-O. (2022). Data from: studying predator foraging mode and hunting success at the individual level with an online videogame. *Behavioral Ecology*. [https://doi.org/10.17605/OSF.IO/WYVRT](https://doi.org/10.17605/OSF.IO/WYVRT)

The code and data to reproduce the analyses presented in the aforementioned paper are freely available on [GitHub](https://github.com/quantitative-ecologist/predator-foraging-mode-videogames).

<br>



# Case study

In the study by Fraser Franco et al. (2022), the authors were interested in mapping the predator's foraging tactics at different levels of biological organization (among environments, individuals, and within individuals). They were also investigating which foraging tactics were most successful, and if their success depended on the behaviour of the prey being hunted.

To do so, they employed multivariate linear mixed models, an extension of standard mixed models where multiple response variables can be modeled simultaneously, and where relationships among the random effects of those response variables are estimated.

Here, we will work with a simpler version of the models presented in the paper. All the analyses performed in the workshop can be reproduced using the files provided in this [GitHub repository](https://github.com/quantitative-ecologist/ComputationEcology-SummerSchool). All analyses in this tutorial are done using the R software, but note that they could also be done in Python or Julia.

*Note : Some code sections are folded to ease the interpretation and allow for a better flow of the work package. You can easily show the code by clicking on the "code" icons that are always displayed on the upper right corner of the outputs.*


## A note on Bayesian inference and MCMC sampling

Bayesian statistics are a whole different way of thinking about how to perform statistical analyses. Here, we will use Bayesian inference for our analyses, so it may be feel bit different than what you are used to if you learned classical (frequentist) statistics. The theory underlying Bayes' theorem and Bayesian inference is far beyond the scope of this tutorial, so please consult the relevant resources in the References section. A very good introduction that we cannot recommend enough is Richard McElreath's famous and amazing [Statistical Rethinking book](https://xcelab.net/rm/statistical-rethinking/). Richard McElreath also publishes [lectures on YouTube](https://www.youtube.com/playlist?list=PLDcUM9US4XdPz-KxHM4XHt7uUVGWWVSus) that are very helpful and well explained.

In this tutorial, will fit all our multivariate models using the package [`brms`](https://paul-buerkner.github.io/brms/), which is an R front-end for the probabilistic language [STAN](https://mc-stan.org/). `brms` uses Hamiltonian Monte Carlo (HMC) and the no-U-turn sampler (NUTS) to estimate the model parameters, which is a specific algorithm in the broader family of Markov Chain Monte Carlo (MCMC) estimation. We highly recommend that you read the [package vignettes](https://paul-buerkner.github.io/brms/articles/index.html) to have a better grasp of what you can do with `brms` and how it works.

In Bayesian inference, you will always see the term "**posterior distribution**". The posterior distribution is a fundamental aspect of Bayesian statistics. It consists of a distribution that contains the plausability of the parameters that the model estimates, conditional on the data. There are many ways in which we can approximate the posterior, but in this tutorial, we will use MCMC. Thus, remember that anytime you see the term "posterior" in this tutorial, we are referring to the distribution of a parameter estimated by the model.

<br>



# The data

The player behaviour data was collected by the videogame company [Behaviour Interactive](https://www.bhvr.com/) between March 20 2019 and June 17 2019. Every player initiated their first match between March 20 and March 22. This dataset summarizes behavioural data from matches played as the predator. For every match, the date (date-hour-minutes), the duration (seconds), the predator player's anonymous ID, the predator's avatar, and the game environment were recorded along with the predator and prey behaviours.

Here is some basic information on the dataset :

- Matches were played exclusively against a group of unknown people.
- Minimum match duration was 5 minutes
- Population of 2 378 players
- 77 047 matches (average: 34 matches per individual, range: 1-1059 matches)
- The average match duration was 11.13 minutes (range: 5-35 min).


## Load the libraries

In this tutorial, we will use the [`data.table`](https://rdatatable.gitlab.io/data.table/index.html) R package for data wrangling. `data.table` is a fast and very useful package for data science in general, and is great for manipulating large datasets. It operates similarly to base R's `data.frame`.

As mentionned before, we will fit all our models using the package [`brms`](https://paul-buerkner.github.io/brms/).

Lastly, we use the [`ggplot2`](https://ggplot2.tidyverse.org/) R package for our plots, and [`ggpubr`](https://rpkgs.datanovia.com/ggpubr/index.html) to combine multiple plots together.

```{r, class.source = "fold-show"}

# libraries
library(data.table)
library(brms)
library(ggplot2)
library(ggpubr)
```


## Import the data

We directly import the data hosted on the public [GitHub](https://github.com/quantitative-ecologist/predator-foraging-mode-videogames) repository into our session.

```{r, class.source = "fold-show"}

# Type the repository's URL
github <- "https://raw.githubusercontent.com/quantitative-ecologist"
repository <- "predator-foraging-mode-videogames"
folder <- "main/data"

# Import the data in our session
data <- fread(
  file.path(
    github, repository,
    folder, "FraserFrancoetal2022-data.csv"
  ),
  select = c(
    "player_id", "avatar_id",
    "hunting_success", "game_duration",
    "speed", "space_covered_rate", "hook_start_time",
    "prey_avg_speed", "prey_avg_space_covered_rate"
  )
)

# Rename variables
setnames(data, "hook_start_time", "latency_1st_capture")
setnames(data, "speed", "pred_speed")
setnames(data, "player_id", "predator_id")
```


## Data exploration

### Data structure

Here is a description of the variables that we will use in our models.

Continuous variables :

- `pred_speed`: the average speed of the predator in meters per second (m/s)
- `space_covered_rate`: the rate of space covered by the predator in the virtual environment in 16 $m^{2}$ tiles per second (t/s)
- `latency_1st_capture`: the time in seconds before the predator captured its first prey 
- `prey_avg_speed`: the average speed of the four prey (m/s)
- `prey_avg_space_covered_rate`: the average rate of space covered by the four prey (t/s)
- `game_duration`: the game duration in seconds (s)

Group variables :

- `predator_id`: the unique ID of an individual predator player
- `avatar_id`: the predator avatar that the player chose for the match

```{r, class.source = "fold-show"}
# Print the data
data

# Inspect the number of avatars
length(unique(data$avatar_id))

# Inspect the number of individual predators
length(unique(data$predator_id))
```

### Distribution of variables
```{r histograms-data, out.width="100%", out.height="70%"}

# Reshape the data to plot multiple histograms -----------------------------------

# Select the needed variables
dat_hist <- data[
  , .(
    pred_speed, space_covered_rate,
    prey_avg_speed, prey_avg_space_covered_rate,
    latency_1st_capture, game_duration
  )
]

# Reshape the table
dat_hist <- melt(
  data = dat_hist,
  variable.name = "variable",
  value.name = "value"
)



# Plot the histograms ------------------------------------------------------------

# Panel labels
labels <- labeller(
  variable =
  c("pred_speed" = "Predator speed",
    "space_covered_rate" = "Rate of space coverage",
    "prey_avg_speed" = "Prey speed",
    "prey_avg_space_covered_rate" = "Prey's rate of space coverage",
    "latency_1st_capture" = "Latency for 1st capture",
    "game_duration" = "Game duration")
)

p <- ggplot(data = dat_hist, aes(x = value)) +
  geom_histogram(col = "black", fill = "gray") +
  xlab("\nValue") +
  ylab("Frequency\n") +
  facet_wrap(~ variable, scales = "free", labeller = labels) +
  theme_bw(base_size = 12) +
  theme(panel.grid = element_blank(), strip.text = element_text(size = 8))

# Show figure
p
```

### Data transformation

We saw that the latency before the first capture and the game duration are somewhat skewed and non Gaussian. In this tutorial, we use basic multivariate mixed-models (the non GLM version), which assume that the residuals are Gaussian. We will thus transform the latency before the first capture to ensure that this assumption is respected. We would usually not need to transform the game duration, but it will help the model to better assess the relationship by spreading the distribution towards the right.

```{r, class.source = "fold-show"}

# Transform our variables
data[, ":=" (
  latency_1st_capture = log(latency_1st_capture + 1),
  game_duration = sqrt(game_duration)
  )
]
```

### Data standardization

Lastly, before proceeding to run the models, we first standardize our variables to mean and unit variance.

```{r, class.source = "fold-show"}

# Standardize the variables
standardize <- function(x) {
  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
}

data[
  , c("Zgame_duration",
      "Zpred_speed",
      "Zspace_covered_rate",
      "Zlatency_1st_capture",
      "Zprey_avg_speed", 
      "Zprey_avg_space_covered_rate") :=
  lapply(.SD, standardize),
  .SDcols = c(4:9)
]
```

<br>



# Fitting multivariate mixed-effects models with `brms`


## Building the models

We now build the multivariate mixed-effects models for two predator foraging behaviours and one measure of foraging performance :

- the predator's average speed (`pred_speed`)
- the rate of space covered by the predator (`space_covered_rate`)
- the time in seconds before the predator captured its first prey (`latency_1st_capture`)

As you will see, the two models follow a very similar structure.

**In the first model**, we are interested in modelling the predator foraging behaviour without any effects of the prey. The goal is to describe the predator's foraging tactics in its most "basic" form. We also want to estimate the relationship between foraging behaviour and performance. We control for the predator player's avatar in this model as it could influence the player's playstyle in a match, but we won't make any biological inference from it.

**In the second model**, we build upon the first model, but we include the prey's behaviour as fixed effects. This will help us assess whether the predator's foraging tactics and performance described in the first model change after removing the effect of the prey's behaviour. Again, we control for the predator player's avatar.

If we see a difference in the predator's foraging tactics between the two models, then we can infer that the prey are driving the predator's foraging tactics and performance. 

Both models can be described mathematically with the following equations :

\begin{align}
    speed &= X_\ b + M\ av + N\ id + e \tag{eqn. 1} \\
    space &= X_\ b + M\ av + N\ id + e \tag{eqn. 2} \\
    latency &= X_\ b + M\ av + N\ id + e \tag{eqn. 3} 
\end{align}

where $av$, and $id$ are the vectors of random avatar, and random individual identity effects associated with their incidence matrices $M$ and $N$. $b$ is the vector of fixed effects with its incidence matrix $X$. Lastly, $e$ is the error term corresponding to the residuals. In the first model, the fixed effects correspond only to a general intercept + the game duration for the latency before the first capture. In the second model, the fixed effects include a global intercept along with the slope terms of the prey's speed and rate of space covered + the game duration for the latency before the first capture.

The random effects and residuals follow a multivariate Gaussian distribution, where $\Sigma$ is a 3x3 variance-covariance matrix:

\begin{align}
\begin{bmatrix}
    av_{speed} \\ av_{space} \\ av_{latency}
\end{bmatrix}
&\sim MVN(0,\ \Sigma_{av}): \Sigma_{av} =
\begin{bmatrix}
    V_{av_{speed}} & & \\
    Cov_{av_{speed}\ av_{space}} & V_{av_{space}} & \\
    Cov_{av_{speed}\ av_{latency}} & Cov_{av_{space}\ av_{latency}} & V_{av_{latency}}
\end{bmatrix} \tag{eqn. 4} \\

\begin{bmatrix}
    id_{speed} \\ id_{space} \\ id_{latency}
\end{bmatrix}
&\sim MVN(0,\ \Sigma_{id}): \Sigma_{id} =
\begin{bmatrix}
    V_{id_{speed}} & & \\
    Cov_{id_{speed}\ id_{space}} & V_{id_{space}} & \\
    Cov_{id_{speed}\ id_{latency}} & Cov_{id_{space}\ id_{latency}} & V_{id_{latency}}
\end{bmatrix} \tag{eqn. 5} \\

\begin{bmatrix}
    e_{speed} \\ e_{space} \\ e_{latency}
\end{bmatrix}
&\sim MVN(0,\ \Sigma_{e}): \Sigma_{e} =
\begin{bmatrix}
    V_{e_{speed}} & & \\
    Cov_{e_{speed}\ e_{space}} & V_{e_{space}} & \\
    Cov_{e_{speed}\ e_{latency}} & Cov_{e_{space}\ e_{latency}} & V_{e_{latency}}
\end{bmatrix} \tag{eqn. 6}
\end{align}

The variance-covariance matrices (i.e. equations 4 to 6) enable us to determine the structure of the predator's foraging tactics and performance. At the individual level (i.e. $id$), if we see that the predator's speed and latency before the first capture are negatively correlated, then we can infer that faster predators are more efficient because they take less time to capture their first prey. On the other hand, the residual ($e$) correlations tell a similar story, but at the within-individual level. Thus, using the same correlation as an example, we could say that matches in which predators were faster were also matches in which they were more efficient at capturing the prey. Alternatively, if individuals were slower in other matches, then they were not as efficient.

In the next subsections, we will write our models using the `brms` syntax. As you will see, we will use the `bf()` function (for "**b**rms **f**ormula") in `brms` to write the model formulas. We will employ these naming conventions for the equations describing the predator's traits and performance (i.e. equation 1 to 3) :

- Speed (`speed_form1` for model 1) (`speed_form2` for model 2)
- Rate of space covered (`space_form1` for model 1) (`space_form2` for model 2)
- Latency before the first capture (`hook_form1` for model 1) (`hook_form2` for model 2)

### Model 1

The following block of code shows the formulas for the three traits we are analyzing for model 1.

For the predator's speed and rate of space covered, the model estimates a general intercept (i.e. the `1 +` term) and two random effects which are the `avatar_id` and the `predator_id`. The model for the predator's latency before the first capture follows the same structure, but we include the match duration (`Zgame_duration`) as a fixed effect to control for differences in game length.

The `a` and `b` notation indicate that we want the model to estimate correlations among the random effects. Thus, the `avatar_id` and `predator_id` random effects will be correlated across the three traits. Note that in `brms`, you could have used any letter to estimate the correlations, as long as you keep the same letter across sub models.

```{r, class.source = "fold-show"}

# Model for the predator's speed
speed_form1 <- bf(
  Zpred_speed ~
  1 +
  (1 | a | avatar_id) +
  (1 | b | predator_id)
) + gaussian()

# Model for the rate of space covered by the predator
space_form1 <- bf(
  Zspace_covered_rate ~
  1 +
  (1 | a | avatar_id) +
  (1 | b | predator_id)
) + gaussian()

# Model for the latency before the 1st capture
hook_form1 <- bf(
  Zlatency_1st_capture ~
  1 +
  Zgame_duration +
  (1 | a | avatar_id) +
  (1 | b | predator_id)
) + gaussian()
```

### Model 2

The second model follows the same structure as model 1, but includes the average speed and rate of space covered of the prey group (`Zprey_avg_speed` and `Zprey_avg_space_covered_rate`) as fixed effects for the three predator traits.

```{r, class.source = "fold-show"}

# Model for the predator's speed
speed_form2 <- bf(
  Zpred_speed ~
  1 +
  Zprey_avg_speed +
  Zprey_avg_space_covered_rate +
  (1 | a | avatar_id) +
  (1 | b | predator_id)
) + gaussian()

# Model for the rate of space covered by the predator
space_form2 <- bf(
  Zspace_covered_rate ~
  1 +
  Zprey_avg_speed +
  Zprey_avg_space_covered_rate +
  (1 | a | avatar_id) +
  (1 | b | predator_id)
) + gaussian()

# Model for the latency before the 1st capture
hook_form2 <- bf(
  Zlatency_1st_capture ~
  1 +
  Zprey_avg_speed +
  Zprey_avg_space_covered_rate +
  Zgame_duration +
  (1 | a | avatar_id) +
  (1 | b | predator_id)
) + gaussian()
```

### Setting up priors

Lastly, the Bayesian approach requires that we define priors for the parameters that the models will estimate. In short, priors are a probability distribution indicating the prior plausibilities of an uncertain quantity before evidence is taken into account. They are usually assumed and carefully chosen based on the scientific knowledge of the system to help the model at estimating the parameters' posterior distributions. Thus, they can be seen as an assumption of how your system of interest works.

Here is an example. Suppose that you want to estimate the relationship between species richness and forest cover using linear regression. Because we usually know that more habitat should support more species, we could use a prior on the slope term defined as a Gaussian distribution with mean of 0.5 and standard deviation of 1. This prior would be telling our model that the slope (relationship between species richness and land cover) should be positive with the most plausible value being 0.5, indicating a 0.5 unit increase in species richness for each unit of forest cover. This would be called a weakly informative prior, because the standard deviation of 1 still allows the model to search for a fair range of slope values around the mean of 0.5.

Here is a simulated example to see what this prior looks like :
```{r sim-prior}
# n = 1000
set.seed(123)
dat <- data.frame(vec = rnorm(1000, mean = 0.5, sd = 1))
avg <- mean(dat$vec)

p1 <- ggplot(dat, aes(x = vec)) +
  geom_histogram(
    aes(y = after_stat(density)),
    col = "black", fill = "gray"
  ) +
  geom_density(alpha = 0.2, fill = "dodgerblue") +
  geom_vline(
    xintercept = avg,
    linetype = "dashed", linewidth = 1.5,
    col = "black"
  ) +
  ggtitle("n = 1000") +
  xlab("\npossible slope values") +
  ylab("density\n") +
  theme_bw(base_size = 12) +
  theme(panel.grid = element_blank())
p1
```

You can see that the range of plausible values for the slope ranges from -2.31 to 3.74 with the most plausible value being 0.5 (i.e. the black dashed line).

In our case, because this was the first time that we modelled data in *Dead by Daylight*, we used weakly informative priors which impose constrains on the parameter estimation while also leaving it some freedom. Moreover, because we have a large dataset, the data should drive the posterior distribution of parameter values more than the prior. For more information on priors, see the relevant sections in @McElreath2020.

```{r, class.source = "fold-show"}

# Priors for model 1
priors1 <- c(
  # priors on fixed effects
  set_prior(
    "normal(0, 2)",
    class = "b",
    coef = "Zgame_duration",
    resp = "Zlatency1stcapture"
  ),
  # priors on standard deviations (brms automatically detects half-normal)
  # half-normal because standard deviations have a lower bound of 0
  set_prior(
    "normal(0, 1)",
    class = "sd", # applies to all variance parameters
    resp = c("Zpredspeed", "Zspacecoveredrate", "Zlatency1stcapture")
  ),
  # priors on the variance-covariance (correlation) matrices
  set_prior(
    "lkj(2)",
    class = "cor",
    group = "avatar_id"
  ),
  set_prior(
    "lkj(2)",
    class = "cor",
    group = "predator_id"
  )
)

# Priors for model 2
priors2 <- c(
  priors1,
  # priors on the new fixed effects of prey behaviour
  set_prior(
    "normal(0, 2)",
    class = "b",
    coef = c("Zprey_avg_speed", "Zprey_avg_space_covered_rate"),
    resp = c("Zpredspeed", "Zspacecoveredrate", "Zlatency1stcapture",
             "Zpredspeed", "Zspacecoveredrate", "Zlatency1stcapture")
  )
)
```


## Run the models

**Import the model outputs into our session**

Estimating posterior parameters with MCMC can take a long time. Moreover, the more data you have, the longer the computation will be. For example, in a single script, both models together took around 1.5 hours to run on a supercomputer with 64Gb of RAM and 48 computer cores. So the time would be longer in most cases since standard laptops usually have 16Gb of RAM with 4 computer cores.

Thus, whenever your models take some time to run, you should save their results (e.g. as `.rds` files or any other type depending on your programming language) when they have finished running. You can then reupload the model outputs as R objects into an R session and manipulate them for your needs (e.g. for checks, plots, and tables).

This is what we do here, we will directly import the two model outputs from the "models" folder (`.rds` files) as R objects into our session. 

```{r, class.source = "fold-show"}

path <- file.path(getwd(), "models")

fit1 <- readRDS(file.path(path, "mv_model1.rds"))
fit2 <- readRDS(file.path(path, "mv_model2.rds"))
```

### Code to run model 1

Here is the `brms` code that was used to run the first model (`fit1`) that we just imported. We used the `brm()` function to parameterize and initiate the sampling.

```{r eval = FALSE, class.source = "fold-show"}

# Model 1
fit1 <- brm(
  # The three model formulas are summed
  speed_form1 +
  space_form1 +
  hook_form1 +
  # To estimate residual correlations
  # i.e. inference about behavioural plasticity
  set_rescor(TRUE),
  # MCMC settings to obtain 1000 posterior samples
  # (iter - warmups) / thin * chains
  warmup = 500,
  iter = 2500,
  thin = 8,
  chains = 4,
  # Initialize parameter values at 0
  inits = "0",
  # Within-chain parallelization :
  # Use only if you have access to multiple computer cores
  threads = threading(10),
  # Software backend for MCMC estimation
  backend = "cmdstanr",
  seed = 123,
  prior = priors1,
  # Helps MCMC convergence
  control = list(adapt_delta = 0.95),
  # Sample priors to later compare priors vs posterior distributions
  sample_prior = TRUE,
  data = data
)

# Save the object to a specified folder path
my_path <- file.path(getwd(), "your_folder")
saveRDS(fit1, file = file.path(my_path, "mv_model1.rds"))
```

### Code to run model 2

And here is the `brms` code used to fit the second model (`fit2`), where we controlled for the prey's behaviour.

```{r eval = FALSE, class.source = "fold-show"}

# Model 1
fit2 <- brm(
  # The three model formulas are summed
  speed_form2 +
  space_form2 +
  hook_form2 +
  # To estimate residual correlations
  # i.e. inference about behavioural plasticity
  set_rescor(TRUE),
  # MCMC settings to obtain 1000 posterior samples
  # (iter - warmups) / thin * chains
  warmup = 500,
  iter = 2500,
  thin = 8,
  chains = 4,
  # Initialize parameter values at 0
  inits = "0",
  # Within-chain parallelization :
  # Use only if you have access to multiple computer cores
  threads = threading(10),
  # Software backend for MCMC estimation
  backend = "cmdstanr",
  seed = 123,
  prior = priors,
  # Helps MCMC convergence
  control = list(adapt_delta = 0.95),
  # Sample priors to later compare priors vs posterior distributions
  sample_prior = TRUE,
  data = data
)

# Save the object to a specified folder path
my_path <- file.path(getwd(), "your_folder")
saveRDS(fit2, file = file.path(my_path, "mv_model2.rds"))
```


## Model diagnostics

Now that our models have finished running, it is paramount that we do some checks to confirm that the parameters are reliable. Completing these steps is crucial to ensure that the biological interpretations we will do afterwards make sense. Otherwise, you could be up for unpleasant surprises.

### Inspect model convergence

We first inspect the convergence of the MCMC chains for every parameter of interest using trace plots. We can deduce that the chains converged well when the trace plots are homogeneous. For simplicity, we will only inspect the chains of the first model, but remember that we should do the same steps for the second model too.

We start by extracting the model parameters that we want in a `data.frame`.

```{r, class.source = "fold-show"}

params <- as_draws_df(
  fit1, add_chain = TRUE,
  variable = c("^b_", "^sd", "^cor_", "^rescor_"),
  regex = TRUE
)
```

Inspect the trace plots for the beta parameters (intercepts + slopes)

```{r trace1, out.width="90%", out.height="70%"}
bayesplot::mcmc_trace(params, regex_pars = "b", np = nuts_params(fit1))
```

Inspect the trace plots for the standard deviation parameters (random effects)

```{r trace2, out.width="90%", out.height="50%"}
bayesplot::mcmc_trace(params, regex_pars = "sd", np = nuts_params(fit1))
```

Inspect the trace plots for the correlated random effects + the residual correlations

```{r trace3, out.width="90%", out.height="70%"}
bayesplot::mcmc_trace(params, regex_pars = "cor", np = nuts_params(fit1))
```

### Rhat and effective sample size

Another important convergence check in analyses requiring MCMC sampling is to evaluate the $\hat{R}$ and effective sample sizes of each parameter of interest. In @Burkner2017, we can read that the effective sample size is : "the number of independent samples from the posterior distribution that would be expected to yield the same standard error of the posterior mean as is obtained from the dependent samples returned by the MCMC algorithm". In `brms`, the model summary provides an estimate of the bulk and tail effective sample sizes. The `Bulk_ESS` diagnoses the sampling efficiency of the bulk of the posterior (i.e. median or mean), while the `Tail_ESS` diagnoses the sampling efficiency of the tails of the posterior (i.e. 5% and 95% quantiles). We use a threshold of <100 effective sample sizes as a decision rule for whether the chains converged for the parameters [@Vehtari.etal2021a]. Conversely, the $\hat{R}$ is the potential scale reduction factor on split chains, which is a common diagnostic tool for whether the chains converged [@gelmanBayesianDataAnalysis2013;@Burkner2017]. Different versions and thresholds have been proposed for this measure [@gelmanInferenceIterativeSimulation1992;@gelmanBayesianDataAnalysis2013;@Vehtari.etal2021a], but we will use the most parsimonious one suggested by @Vehtari.etal2021a with a treshold set to <1.01.

In `brms`, the $\hat{R}$, the `Bulk_ESS`, and the `Tail_ESS` always appear beside the parameters' posterior means (not shown here) displayed using the `summary()` function. For simplicity, we assemble them in a `data.table`. We will inspect the values for the fixed effects, followed by those of the random effects + correlations.

Here are the values for the fixed effects:

```{r}

# Prepare a data.table for model1
checks1_1 <- data.table(
  Model = "model1",
  round(summary(fit1)$fixed[, c(5:7)], digits = 3),
  keep.rownames = TRUE
)
setnames(checks1_1, old = "rn", new = "Parameter")

# Prepare a data.table for model1
checks1_2 <- data.table(
  Model = "model2",
  round(summary(fit2)$fixed[, c(5:7)], digits = 3),
  keep.rownames = TRUE
)
setnames(checks1_2, old = "rn", new = "Parameter")

# Combine as one table
checks1 <- rbind(checks1_1, checks1_2)
checks1
```

We then inspect the values for the `avatar_id` random effect:

```{r}

checks2_1 <- data.table(
  Model = "model1",
  round(summary(fit1)$random$avatar_id[, c(5:7)], digits = 3),
  keep.rownames = TRUE
)
setnames(checks2_1, old = "rn", new = "Parameter")

checks2_2 <- data.table(
  Model = "model2",
  round(summary(fit2)$random$avatar_id[, c(5:7)], digits = 3),
  keep.rownames = TRUE
)
setnames(checks2_2, old = "rn", new = "Parameter")

checks2 <- rbind(checks2_1, checks2_2)
checks2
```

Lastly, we inspect the values for the `predator_id` random effect:

```{r}

checks3_1 <- data.table(
  Model = "model1",
  round(summary(fit1)$random$predator_id[, c(5:7)], digits = 3),
  keep.rownames = TRUE
)
setnames(checks3_1, old = "rn", new = "Parameter")

checks3_2 <- data.table(
  Model = "model2",
  round(summary(fit2)$random$predator_id[, c(5:7)], digits = 3),
  keep.rownames = TRUE
)
setnames(checks3_2, old = "rn", new = "Parameter")

checks3 <- rbind(checks3_1, checks3_2)
checks3
```

Looking at the three tables, it appears that all the values fall below the tresholds, which confirms that the chains have converged well.

### Inspect the residuals

Here, we inspect our linear model assumptions by :

- confirming that the residuals follow a gaussian distribution
- confirming that the variance of the residuals is homogeneous

We start by extracting the fitted values and residuals of both models

```{r resid-mod1, cache = TRUE, class.source = "fold-show"}

# Residuals for model 1
fitted1a <- fitted(fit1, resp = "Zpredspeed")[, 1]
resid1a <- residuals(fit1, resp = "Zpredspeed")[, 1]

fitted1b <- fitted(fit1, resp = "Zspacecoveredrate")[, 1]
resid1b <- residuals(fit1, resp = "Zspacecoveredrate")[, 1]

fitted1c <- fitted(fit1, resp = "Zlatency1stcapture")[, 1]
resid1c <- residuals(fit1, resp = "Zlatency1stcapture")[, 1]
```

```{r resid-mod2, cache = TRUE, class.source = "fold-show"}
# Residuals for model 2
fitted2a <- fitted(fit2, resp = "Zpredspeed")[, 1]
resid2a <- residuals(fit2, resp = "Zpredspeed")[, 1]

fitted2b <- fitted(fit2, resp = "Zspacecoveredrate")[, 1]
resid2b <- residuals(fit2, resp = "Zspacecoveredrate")[, 1]

fitted2c <- fitted(fit2, resp = "Zlatency1stcapture")[, 1]
resid2c <- residuals(fit2, resp = "Zlatency1stcapture")[, 1]

```

We then produce the plots and combine them together to inspect their distribution.

```{r residplot-mod1, fig.height = 5, fig.width = 15}

assum1a <- ggplot() +
  geom_point(aes(x = fitted1a, y = resid1a), shape = 20, alpha = 0.05) +
  scale_y_continuous(breaks = seq(-6, 6, 2), limits = c(-7.55, 6)) +
  ggtitle("Speed - model 1") +
  xlab("Fitted values") + ylab("Residuals") +
  theme_bw() +
  theme(
    title = element_text(size = 15),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 15),
    panel.grid = element_blank()
    )
assum1a <- ggExtra::ggMarginal(assum1a, type = "histogram", margins = "y")

assum1b <- ggplot() +
  geom_point(aes(x = fitted1b, y = resid1b), shape = 20, alpha = 0.05) +
  scale_y_continuous(breaks = seq(-6, 6, 2), limits = c(-7.55, 6)) +
  ggtitle("Space covered - model 1") +
  xlab("Fitted values") + ylab("Residuals") +
  theme_bw() +
  theme(
    title = element_text(size = 15),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 15),
    panel.grid = element_blank()
    )
assum1b <- ggExtra::ggMarginal(assum1b, type = "histogram", margins = "y")

assum1c <- ggplot() +
  geom_point(aes(x = fitted1c, y = resid1c), shape = 20, alpha = 0.05) +
  scale_y_continuous(breaks = seq(-6, 6, 2), limits = c(-7.55, 6)) +
  ggtitle("Latency 1st capture - model 1") +
  xlab("Fitted values") + ylab("Residuals") +
  theme_bw() +
  theme(
    title = element_text(size = 15),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 15),
    panel.grid = element_blank()
    )
assum1c <- ggExtra::ggMarginal(assum1c, type = "histogram", margins = "y")

# Combine all plots into a single figure
resids1 <- ggarrange(
  assum1a, assum1b, assum1c,
  ncol = 3, nrow = 1
)

resids1
```

```{r residplot-mod2, fig.height = 5, fig.width = 15}
assum2a <- ggplot() +
  geom_point(aes(x = fitted2a, y = resid2a), shape = 20, alpha = 0.05) +
  scale_y_continuous(breaks = seq(-8, 6, 2), limits = c(-8, 6)) +
  ggtitle("Speed - model 2") +
  xlab("Fitted values") + ylab("Residuals") +
  theme_bw() +
  theme(
    title = element_text(size = 15),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 15),
    panel.grid = element_blank()
    )
assum2a <- ggExtra::ggMarginal(assum2a, type = "histogram", margins = "y")

assum2b <- ggplot() +
  geom_point(aes(x = fitted2b, y = resid2b), shape = 20, alpha = 0.05) +
  scale_y_continuous(breaks = seq(-8, 6, 2), limits = c(-8, 6)) +
  ggtitle("Space covered - model 2") +
  xlab("Fitted values") + ylab("Residuals") +
  theme_bw() +
  theme(
    title = element_text(size = 15),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 15),
    panel.grid = element_blank()
    )
assum2b <- ggExtra::ggMarginal(assum2b, type = "histogram", margins = "y")

assum2c <- ggplot() +
  geom_point(aes(x = fitted2c, y = resid2c), shape = 20, alpha = 0.05) +
  scale_y_continuous(breaks = seq(-8, 6, 2), limits = c(-8, 6)) +
  ggtitle("Latency 1st capture - model 2") +
  xlab("Fitted values") + ylab("Residuals") +
  theme_bw() +
  theme(
    title = element_text(size = 15),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 15),
    panel.grid = element_blank()
    )
assum2c <- ggExtra::ggMarginal(assum2c, type = "histogram", margins = "y")

# Combine all plots into a single figure
resids2 <- ggarrange(
  assum2a, assum2b, assum2c,
  ncol = 3, nrow = 1, heights = c(0.5, 0.5, 0.5)
)

resids2
```

### Inspect model fit

We can then investigate how well the models predicted the data using [posterior predictive checks](https://mc-stan.org/bayesplot/reference/PPC-overview.html). Posterior predictive checks use simulated data from the posterior predictive distribution of a model and compares it to the raw data used to fit the model. @gabryVisualizationBayesianWorkflow2019 suggest that if a model is a good fit, then the data generated by it should ressemble the data that was observed. Here, $y$ is the distribution of our observed data, and $y_{rep}$ is the distribution of data simulated from the model's posterior predictive distribution. 

Producing the plots may take some time depending on the complexity of your model and the size of your data. You can specify the number of draws to display using the `ndraws` argument within the `pp_check()` function.

```{r ppchek1-mod1, cache = TRUE}

# Model 1
pp1a <- pp_check(fit1, resp = "Zpredspeed") +
  ggtitle("Speed")
pp1b <- pp_check(fit1, resp = "Zspacecoveredrate") +
  ggtitle("Rate of space covered")
pp1c <- pp_check(fit1, resp = "Zlatency1stcapture") +
  ggtitle("Latency 1st capture")
```

```{r ppchek1-mod2, cache = TRUE}
# Model 2
pp2a <- pp_check(fit2, resp = "Zpredspeed") +
  ggtitle("Speed")
pp2b <- pp_check(fit2, resp = "Zspacecoveredrate") +
  ggtitle("Rate of space covered")
pp2c <- pp_check(fit2, resp = "Zlatency1stcapture") +
  ggtitle("Latency 1st capture")
```

We now assemble the posterior predictive checks plots into one figure for model 1

```{r ppcheck1-fig1, out.width="70%", out.height="70%"}

fig1 <- ggarrange(
  pp1a, pp1b, pp1c,
  ncol = 2, nrow = 2,
  common.legend = TRUE
)

fig1
```

Posterior predictive checks plots into one figure for model 2

```{r ppcheck1-fig2, out.width="70%", out.height="70%"}

fig2 <- ggarrange(
  pp2a, pp2b, pp2c,
  ncol = 2, nrow = 2,
  common.legend = TRUE
)

fig2
```

If the model is a good fit, we should see a strong overlap between the curves, which is mostly the case here except for the predator's speed. For speed, we see that our observed data (i.e. $y$) is a bit off on the right compared to the simulated data from our model (i.e. $y_{rep}$). We could thus in theory adjust the model in some way to increase it's predictive accuracy.

### Summary

Overall, we can see that :

- the chains converged well
- the model is not too bad at predicting the data 
- and the residuals seem to be OK.

Yet, some improvements could make our models better. For instance, we could use more informative priors based on the scientific knowledge of the system (and other predator-prey systems) to improve the model fit. It is also possible that including other variables in our model could improve the predictions. Sometimes, it can also be helpful to increase the number of iterations in the model and posterior samples to have a better fit.

### Additional checks

While the model verifications that we just did are probably among the most important ones, they cover only a small portion of the checks that you should perform to ensure that your model has been correctly specified. To go further, here is a list of useful links for additional checks : 

- [MCMC diagnostics](https://mc-stan.org/bayesplot/articles/visual-mcmc-diagnostics.html) with the `bayesplot` package
- [Additional posterior predictive checks](https://mc-stan.org/bayesplot/articles/graphical-ppcs.html) with the `bayesplot` package
- [Additional residuals inspections](http://mjskay.github.io/tidybayes/articles/tidybayes-residuals.html) with the `tidybayes` package. For instance, you could inspect the relationship between the residuals and your fixed effects to see if the model failed at describing some features. This will be important for biological interpretations.
- [Leave-one-out cross-validation](https://link.springer.com/article/10.1007/s11222-016-9696-4) using Pareto-smoothed importance sampling for predictive performance and model comparisons. For important references consult the [loo FAQ](https://avehtari.github.io/modelselection/CV-FAQ.html), [the roaches model example](https://avehtari.github.io/modelselection/roaches.html), and the [loo package vignette](http://mc-stan.org/loo/articles/index.html)

Moreover, note that MCMC estimation can come with different convergence problems. Those problems can arise from different processes, but `brms` (and other packages using MCMC) should print warnings outlining the potential problems after the model has finished running. Here is a [useful link](https://mc-stan.org/misc/warnings.html) describing each of those problems and their solutions.

<br>



# Interpret the models' results


## Fixed effects: population-level parameters

Having confirmed that our two models can be trusted, we will first evaluate their fixed effects. We use the `summary()` function to display the posterior means of the fixed effects along with their credible intervals. In `brms`, the fixed effects are called population-level parameters.

The table contains the parameter values of the two models so you can compare them easily. The parameters are the general intercepts along with the slope terms of each covariate.

An important note here is that we are taking a shortcut with this summary. Remember that we use MCMC estimation for our parameters with 1000 posterior samples per parameter. This means that we have a whole posterior distribution for each parameter, which we could summarize with different metrics like its mean, median, or mode. Here, the `summary()` function reports the mean of the posterior distributions. Moreover, the output displays the 95% credible intervals, but that is just a convention. It is often recommended to use a range of intervals to better describe the posterior (e.g. 50%, 80%, and 95%). Richard McElreath suggests that in some instances, it is just better to report the whole posterior distribution. To extract all the parameters' posterior draws from a fitted model in `brms`, you can use the [`as_draws()` function](https://paul-buerkner.github.io/brms/reference/draws-brms.html).

```{r}

# Select the fixed effects values with their 95% CIs in a data.table for model1
fixed1_1 <- data.table(
  Model = "model1",
  round(summary(fit1)$fixed[, c(1, 3, 4)], digits = 3),
  keep.rownames = TRUE
)
setnames(fixed1_1, old = "rn", new = "Parameter")

# Select the fixed effects values with their 95% CIs in a data.table for model2
fixed1_2 <- data.table(
  Model = "model2",
  round(summary(fit2)$fixed[, c(1, 3, 4)], digits = 3),
  keep.rownames = TRUE
)
setnames(fixed1_2, old = "rn", new = "Parameter")

# Combine the results from both models as one table
fixed1 <- rbind(fixed1_1, fixed1_2)

fixed1
```

The fixed effects of the first model show :

- a small but negative relationship between the latency before the first capture and game duration

The fixed effects of the second model show :

- a moderate positive relationship between the predator and the prey's speed
- a small positive relationship between the predator's speed and the prey's space coverage
- a strong negative relationship between the predator's space coverage and the prey's speed
- a very strong positive relationship between the predator and the prey's space coverage
- a small positive relationship between the predator's latency before the first capture and the prey's speed
- a strong positive relationship between the predator's latency before the first capture and the prey's space coverage
- a small but now positive relationship between the latency before the first capture and game duration

We also see that the populations mean (i.e. the Intercepts) of the predator's space coverage and performance is lower in the second model indicating slower space coverage and higher performance when removing the effect of the prey. The predator's mean population speed is higher in the second model.


## Random effects: group-level parameters

### Predator ID : Differences in behaviour among the individual predator players

As we mentionned before, we controlled for the predator player's avatar, which is an artifact of the system since it is a videogame. Because we are not interested in anything biological about this effect, we won't present their results here, and go directly to describe the results for the predator ID (`predator_id`), that is, among individual differences in behaviour. 

In `brms`, the random effects are displayed as standard deviations (`sd`). Thus, the random effects in our models are standard deviations estimated for each predator trait. The value of the standard deviations indicates whether predator players differ in their predicted average behaviours. For example, the value of `0.557` for the predator's speed indicates that there are moderate differences among individuals in their average speed. Thus, some players are slower while others are faster on average.

The correlations (`cor`) between the predator players' average behaviours indicates whether, for example, individuals that were faster also captured their first prey faster (e.g. `cor(Zpredspeed_Intercept,Zlatency1stcapture_Intercept)`).

```{r}

# Select the random effects with the estimated value along with their 95% CIs.
ranefs1 <- data.table(
  Model = "model1",
  round(summary(fit1)$random$predator_id[, c(1, 3, 4)], digits = 3),
  keep.rownames = TRUE
)
setnames(ranefs1, old = "rn", new = "Parameter")

ranefs2 <- data.table(
  Model = "model2",
  round(summary(fit2)$random$predator_id[, c(1, 3, 4)], digits = 3),
  keep.rownames = TRUE
)
setnames(ranefs2, old = "rn", new = "Parameter")

ranefs <- rbind(ranefs1, ranefs2)
ranefs
```

Description des résultats...


## Additional analyses : variance partitionning

courte description du partitionnement de la variance et pointer aux références pertinentes ou à mon article.

<br>



# Summary: ecological inference

Description des résultats obtenus et interprétations biologiques

# References {.unnumbered}

<div id="refs"></div>